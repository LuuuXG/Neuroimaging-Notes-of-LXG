# 人脑成像转录组学（Imaging Transcriptomic）分析实践

## 1. 前言
承接上一篇笔记，记录分析的过程。主要是根据上文提到的综述中Table 1推荐的软件包进行尝试。

![toolbox推荐](Imaging_Transcriptomics_practice_1.png)

研究设计方面，主要参照：[Association between gene expression and altered resting-state functional networks in type 2 diabetes](https://www.frontiersin.org/articles/10.3389/fnagi.2023.1290231/full)

### 需要明确的知识

**Space, Template, Atlas**：学习了这个视频（[几个MRI的概念：Space，Template, Atlas](https://www.bilibili.com/video/BV1zv411A74x/?spm_id_from=333.999.0.0&vd_source=262636e26b325960a8c21f8bb6b74f08)）。个人的理解：Space是为了统一坐标系，比如VBM汇报有统计差异的cluster，会用坐标表示cluster的中心，一般都是MNI空间中的坐标。surface的常见标准空间有fsaverage；Template是为了统一大脑的形状，比如常用的MNI152_2009c（以volume空间为例，是否可以理解为，让个体的每一个voxel的位置都对应到标准模板中一个voxel的位置？（不考虑重采样的情况下））；Atlas和Parcellations是一个概念（Parcellations似乎在这里更加常见），比如有在MNI空间中的AAL模板，就表示了哪些坐标位置可以被归为哪个脑区。但我其实还是不能完全分辨这三者的区别，比如用SPM做VBM得到的结果，就可以查看cluster是属于哪个脑区，那这是用的哪个atlas呢？

## 2. 获取脑区-基因表达矩阵

### abagen

官方文档：[abagen: A toolbox for the Allen Brain Atlas genetics data](https://abagen.readthedocs.io/en/stable/)

abagen是众多影像转录组学工具包的基础之一。用AHBA可以获得region×gene的矩阵。由于默认的是Desikan-Killiany atlas，先尝试的就是用默认的DK图谱完成后续分析。

参照User guide，推荐的是将abagen作为python library使用。

#### 安装

```python
pip install abagen
```

#### 下载并检查原始数据

我预先创建了本地路径`F:\Public_dataset\AHBA`。

```python
import abagen

## 1. The Allen Human Brain Atlas dataset ##
# download and fetching the AHBA data to F:\Public_dataset\AHBA
files = abagen.fetch_microarray(data_dir=r'F:\Public_dataset\AHBA', donors='all', verbose=1)

# loading the AHBA data
# this can check the donors and the samples
print(files.keys())
print(sorted(files['9861']))
data = files['9861']
annotation = abagen.io.read_annotation(data['annotation'])
print(annotation)
```

#### 查看Atlas

需要指定一个atlas变量。这里只是根据User guide查看一下自带的atlas，可以根据`print(atlas['image'])`和`print(atlas['info'])`的输出找到图谱和对应的标签文件，可以复制一份用于后续的分析（比如用这个模板提取MRI的对应数据）。

```python
## 2. Defining a parcellation ##
# parcellation means 'atlas'
# in abagen:
#   (1) a NIFTI image in MNI space
#   (2) a tuple of GIFTI images in fsaverage space (and with fsaverage5 resolution!)

# for demonstration purposes: Desikan-Killiany atlas
atlas = abagen.fetch_desikan_killiany()
print(atlas['image'])
print(atlas['info'])

# or the surface version
atlas = abagen.fetch_desikan_killiany(surface=True)
print(atlas['image'])

# or individualized atlas (in donor-native space)
atlas = abagen.fetch_desikan_killiany(native=True)
print(atlas['image'].keys())
print(atlas['image']['9861'])

# and the surface verison of individualized atlas
atlas = abagen.fetch_desikan_killiany(native=True, surface=True)
print(atlas['image'].keys())
print(atlas['image']['9861'])

# non-standard atlas
# check atlas (when define custom atlas?)
# atlas = abagen.images.check_atlas(atlas['image'], atlas['info'])
```

#### 根据Atlas得到各脑区的基因表达数据

因为第一步将原始数据下载到了`F:\Public_dataset\AHBA`中，这里就相应地设置`data_dir`参数。这一步大概会消耗几分钟的时间。

```python
## 3. Parcellating expression data ##
expression = abagen.get_expression_data(atlas['image'], atlas['info'], data_dir=r'F:\Public_dataset\AHBA')
print(expression)

# if using the default command, there will be two missing rows (right frontal pole (label 72) and right temporal pole (label 73))
print(expression.loc[[72, 73]])

# 2 ways to get dense expression data
expression = abagen.get_expression_data(atlas['image'], atlas['info'], data_dir=r'F:\Public_dataset\AHBA',
                                        missing='centroids')

expression = abagen.get_expression_data(atlas['image'], atlas['info'], data_dir=r'F:\Public_dataset\AHBA',
                                        missing='interpolate')

# save the expression data to csv file
expression.to_csv(r'F:\Public_dataset\AHBA\expression.csv')
```

这里只展示了最简单的得到基因表达矩阵的方法，所有参数都采用默认值。可以检查保存的.csv文件。第一列label就是选择的atlas的各个分区，后面所有列都是不同基因的表达数据。

![基因表达结果](Imaging_Transcriptomics_practice_2.png)

值得注意的是，右脑的两个脑区会缺失数据，User guide中介绍了处理方法，上文给出了其中两种填补的方法，这也是一些研究只选择左半球进行分析的原因。其它参数的设置也请参考abagen的User guide。

## 3. 结合影像数据进行分析

### Imaging-transcriptomics （[Imaging-transcriptomics](https://github.com/alegiac95/Imaging-transcriptomics)）


**使用之前的注意事项：**
- **<font color=red>尽量不要在Windows系统上使用（无法进行GSEA）</font>**，直到这个issue（[How to debug “the process cannot access it” when running imt_gsea ?](https://github.com/alegiac95/Imaging-transcriptomics/issues/18)）得到解决。
- [官方文档](https://imaging-transcriptomics.readthedocs.io/en/v.1.1.8/index.html)中也说明了pyhton 3.9+中使用会出现一些问题。实测是不能在python 3.10上顺利安装的。主要问题是其中一个依赖的包h5py在python 3.10上安装会出现问题（[issue #1996](https://github.com/h5py/h5py/issues/1996)）。实测在python 3.9.7上可以正常安装和使用。
- 我在WSL2上使用依然有一些问题，可能与WSL2有关。类似于之前介绍的Freesurfer WMH-SynthSeg使用过程中出现的内存不够的问题。例如在用偏最小二乘回归（PLS）时设置太多成分、GSEA分析过程中，遇到了各种报错导致进程结束。
  
#### 使用Imaging-transcriptomics的命令行（Script usage）进行PLS分析

##### 脑区-基因表达矩阵

Imaging-transcriptomics自带的矩阵在包的`data`文件夹中。里面包含了DK atlas左半球的基因表达矩阵。还未尝试使用Imaging-transcriptomics分析全脑的基因表达矩阵（或者是其它atlas），因为默认的代码中有数值41和34分别指定了全脑和皮层的脑区数目，用其它atlas要修改一些代码。最简单的使用自己得到的矩阵的方法就是将上一步得到的`expression.csv`中的数据替换到`gene_expression_data.csv`中。

![自带矩阵](Imaging_Transcriptomics_practice_3.png)

##### 影像数据

由于我尝试的是默认的全脑ROI，按照文档要求，我准备的是`.txt`文件，每行按顺序是每个脑区的某个影像指标，一共41行。

![影像数据](Imaging_Transcriptomics_practice_4.png)

##### PLS分析

`imagingtranscriptomics --input /mnt/e/Neuroimage/BIDS_TestDataSet/derivatives/freesurfer/mean_values_no_header.txt pls --ncomp 1`

由于我没有指定输出文件夹，默认会在`.txt`的所在文件夹创建输出文件夹。其中`pls_component_1.tsv`是第一个主成分的结果（由于我只设置了一个成分，否则会有_2.tsv，_3.tsv等文件），`pls_analysis.pkl`是该软件包进行后续GSEA使用的数据。检查`pls_component_1.tsv`，结果如下：

![PLS结果](Imaging_Transcriptomics_practice_5.png)

### Neuromaps

## 4. GSEA